{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message='.*looks like a URL.*', category=UserWarning, module='bs4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/alexandravoda/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I'm going to clean the dataset by removing duplicates, empty articles, html tags, stop words and special symbols. I also tried to remove some of the bias I have identified in the exploratory phase. After data cleaning, I lemmatize and tokenize the text content in order to be ready for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  fake  \n",
       "0  December 31, 2017      0  \n",
       "1  December 29, 2017      0  \n",
       "2  December 31, 2017      0  \n",
       "3  December 30, 2017      0  \n",
       "4  December 29, 2017      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake = pd.read_csv('../../data/raw/Fake.csv')\n",
    "df_true = pd.read_csv('../../data/raw/True.csv')\n",
    "\n",
    "df_fake['fake'] = 1\n",
    "df_true['fake'] = 0\n",
    "\n",
    "data = pd.concat([df_true, df_fake], ignore_index=True, sort=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because some of the articles contain html tags, I'll use Beautifulsoup to extract only the text from the existing content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: BeautifulSoup(x).get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll remove text duplicates and entries containing empty texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset size:  44898\n",
      "Dataset size after removing duplicates:  38645\n",
      "Dataset size after removing empty articles:  38644\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial dataset size: \", data.shape[0])\n",
    "data.drop_duplicates(subset=['text'], inplace=True)\n",
    "print(\"Dataset size after removing duplicates: \", data.shape[0])\n",
    "data = data[data['text'].str.len() > 0]\n",
    "print(\"Dataset size after removing empty articles: \", data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to concatenate the title and the article content in order to get a single piece of text. I'll also remove the subject and date fields. This will result in a dataframe containing just the text and its category (fake/true) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  fake\n",
       "0  As U.S. budget fight looms, Republicans flip t...     0\n",
       "1  U.S. military to accept transgender recruits o...     0\n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...     0\n",
       "3  FBI Russia probe helped by Australian diplomat...     0\n",
       "4  Trump wants Postal Service to charge 'much mor...     0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data['title'] + \" \" + data['text']\n",
    "data = data[['text', 'fake']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because \"Reuters\" is specified as an information source in the majority of true articles, I'll delete its occurences in order to remove the bias form the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: \n",
    "            x.replace(\"WASHINGTON \\(Reuters\\)\", \"\").replace(\"(Reuters)\", \"\").replace(\"Reuters\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing urls?\n",
    "# data['text'].apply(lambda x: re.compile(r'https?://\\S+|www\\.\\S+').sub(r'',x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'll remove stop words, punctation marks and other special symbols, because they do not contain useful information that should be used in training. \\\n",
    "Before lemmatization, I need to tokenize the articles contents. This implies splitting the blocks of texts into individual words.\\\n",
    "\\\n",
    "When preparing data for natural language processing tasks, one common preprocessing step is converting the tokens to lowercase. However, for some tasks, keeping the capital letters can make sense. In our case I prefer skipping the lowercase step, because I expect fake news articles to contain more upper-cased words. As we can see below, fake articles have an average of 126.5 uppercase letters, whereas true articles have an average of 89.5 uppercase letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    17453.000000\n",
       "mean       126.543116\n",
       "std         97.254926\n",
       "min          0.000000\n",
       "25%         79.000000\n",
       "50%        103.000000\n",
       "75%        143.000000\n",
       "max       2832.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of uppercase letters in fake articles\n",
    "data[data['fake'] == 1]['text'].apply(lambda x: sum(1 for c in x if c.isupper())).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    21191.000000\n",
       "mean        89.539144\n",
       "std         61.260820\n",
       "min          4.000000\n",
       "25%         43.000000\n",
       "50%         78.000000\n",
       "75%        117.000000\n",
       "max       1294.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of uppercase letters in true articles\n",
    "data[data['fake'] == 0]['text'].apply(lambda x: sum(1 for c in x if c.isupper())).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english') + list(string.punctuation))\n",
    "data['text'] = data['text'].apply(lambda x: [token for token in word_tokenize(x) if token not in stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can continue with the lemmatization step that will convert tokens obtained at the previous step to their base form, removing their inflectional endings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "data['text'] = data['text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[As, U.S., budget, fight, loom, Republicans, f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[U.S., military, accept, transgender, recruit,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[Senior, U.S., Republican, senator, 'Let, Mr.,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[FBI, Russia, probe, helped, Australian, diplo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[Trump, want, Postal, Service, charge, 'much, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44115</td>\n",
       "      <td>[The, White, House, The, Theatrics, ‘, Gun, Co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44116</td>\n",
       "      <td>[Activists, Terrorists, How, Media, Controls, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44117</td>\n",
       "      <td>[BOILER, ROOM, –, No, Surrender, No, Retreat, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44118</td>\n",
       "      <td>[Federal, Showdown, Looms, Oregon, After, BLM,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44119</td>\n",
       "      <td>[A, Troubled, King, Chicago, ’, Rahm, Emanuel,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38644 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  fake\n",
       "0      [As, U.S., budget, fight, loom, Republicans, f...     0\n",
       "1      [U.S., military, accept, transgender, recruit,...     0\n",
       "2      [Senior, U.S., Republican, senator, 'Let, Mr.,...     0\n",
       "3      [FBI, Russia, probe, helped, Australian, diplo...     0\n",
       "4      [Trump, want, Postal, Service, charge, 'much, ...     0\n",
       "...                                                  ...   ...\n",
       "44115  [The, White, House, The, Theatrics, ‘, Gun, Co...     1\n",
       "44116  [Activists, Terrorists, How, Media, Controls, ...     1\n",
       "44117  [BOILER, ROOM, –, No, Surrender, No, Retreat, ...     1\n",
       "44118  [Federal, Showdown, Looms, Oregon, After, BLM,...     1\n",
       "44119  [A, Troubled, King, Chicago, ’, Rahm, Emanuel,...     1\n",
       "\n",
       "[38644 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the preprocessed data in a separate file that will be later used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../../data/processed/data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
